{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "title": "LLM Response Schema",
  "description": "Unified response format from all LLM providers",
  "type": "object",
  "required": ["content", "model", "provider", "tokens_used"],
  "properties": {
    "content": {
      "type": "string",
      "description": "Generated text content from the LLM"
    },
    "model": {
      "type": "string",
      "description": "Model that generated the response",
      "examples": [
        "claude-3-5-sonnet-20241022",
        "qwen2.5:7b-instruct-q4_0"
      ]
    },
    "provider": {
      "type": "string",
      "enum": ["claude", "ollama", "openai"],
      "description": "Provider that generated the response"
    },
    "tokens_used": {
      "type": "integer",
      "minimum": 0,
      "description": "Total tokens used (input + output)"
    },
    "cost_usd": {
      "type": "number",
      "minimum": 0,
      "description": "Cost in USD (if cloud provider)"
    },
    "latency_ms": {
      "type": "number",
      "minimum": 0,
      "description": "Response latency in milliseconds"
    },
    "metadata": {
      "type": "object",
      "description": "Additional provider-specific metadata",
      "properties": {
        "input_tokens": {
          "type": "integer",
          "minimum": 0
        },
        "output_tokens": {
          "type": "integer",
          "minimum": 0
        },
        "stop_reason": {
          "type": "string",
          "enum": ["end_turn", "max_tokens", "stop_sequence", "content_filter"]
        }
      },
      "additionalProperties": true
    }
  },
  "additionalProperties": false
}
