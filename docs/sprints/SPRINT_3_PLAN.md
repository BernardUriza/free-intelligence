# Sprint 3 (SPR-2025W45-46) - Abstracci√≥n LLM

**Inicio**: 2025-10-28 (AHORA - Bernard tiene 5h disponibles)
**Fin**: 2025-10-29 (1-2 d√≠as, flexible)
**Tema**: "LLM Abstraction Layer - Preparaci√≥n para Offline-First"
**Estado**: EN EJECUCI√ìN ‚úÖ
**Roadmap**: Este es el **Sprint 1 del Roadmap Offline-First** (ver `ROADMAP_OFFLINE_FIRST.md`)

---

## üéØ Visi√≥n del Sprint (ACTUALIZADA - Offline-First)

Sprint 3 marca la **transici√≥n cr√≠tica hacia autonom√≠a arquitect√≥nica**. No es solo "hacer funcionar Claude API" - es **dise√±ar la abstracci√≥n que nos libere de cualquier proveedor SaaS**.

**Cambio de Filosof√≠a**:
- ‚ùå **Antes**: "Implementar Claude API y usarlo"
- ‚úÖ **Ahora**: "Abstraer LLM para que Claude sea solo 1 de N proveedores"

**Objetivo Principal**:
1. **Interfaz √∫nica LLM**: `llm.generate()`, `llm.embed()`, `llm.summarize()`
2. **Router inteligente**: Selecci√≥n de provider (Claude hoy, Ollama ma√±ana)
3. **Policy-driven**: Presupuestos, timeouts, fallback en `fi.policy.yaml`
4. **Future-proof**: Cuando instalemos Ollama (Sprint 3 roadmap), solo cambiar config

**Flujo Objetivo**: **Prompt ‚Üí Router ‚Üí [Claude | Ollama | ...] ‚Üí Corpus ‚Üí Search/Export**

---

## üìä An√°lisis Post-Sprint 2

### Velocity Observada

| Sprint | Horas Est | Horas Reales | Cards | Velocity |
|--------|-----------|--------------|-------|----------|
| Sprint 1 | 18h | 1.05h | 5 | 0.06 |
| Sprint 2 | ~40h | ~8h | 12 | 0.20 |
| **Promedio** | **~29h** | **~4.5h** | **8.5** | **0.13** |

**Observaciones**:
- Velocity mejor√≥ 3.3x entre Sprint 1 y 2
- Sprint 2 se complet√≥ en **3/15 d√≠as** (20% del tiempo planificado)
- Bernard tiene alta capacidad de ejecuci√≥n en sesiones concentradas
- Estimaciones consistentemente pesimistas (factor ~5-8x)

### Lecciones Aprendidas

‚úÖ **Funcion√≥ bien**:
- Cards peque√±as y bien definidas (1-5h est)
- Foco en pol√≠ticas y enforcement (AST validators)
- Tests unitarios comprehensivos
- Documentaci√≥n inline durante implementaci√≥n
- Sprint-close automation

‚ö†Ô∏è **Mejorar**:
- Estimar con velocity real (~0.15-0.20, no 0.06)
- Menos buffer time (Bernard ejecuta r√°pido)
- Definir criterios de aceptaci√≥n m√°s espec√≠ficos
- Testing E2E automatizado (no solo unit tests)

---

## üèóÔ∏è Arquitectura Objetivo Sprint 3

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Capa 5: User Interface (CLI)          ‚îÇ
‚îÇ  ‚úÖ Comandos b√°sicos                    ‚îÇ
‚îÇ  üéØ NEW: fi chat, fi search, fi export ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Capa 4: LLM Integration                ‚îÇ
‚îÇ  üéØ NEW: LLM Router (anthropic)         ‚îÇ
‚îÇ  üéØ NEW: Auto-audit logging             ‚îÇ
‚îÇ  üéØ NEW: Cost tracking                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Capa 3: Data Operations                ‚îÇ
‚îÇ  ‚úÖ Append interaction (Sprint 1)       ‚îÇ
‚îÇ  üéØ NEW: Semantic search (embeddings)   ‚îÇ
‚îÇ  üéØ NEW: Export engines (MD, JSON)      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Capa 2: Foundation (Sprint 1+2)        ‚îÇ
‚îÇ  ‚úÖ HDF5 Schema, Audit Logs, Policies   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìã Cards Propuestas (Tier System)

### Tier 1: LLM Abstraction Layer (CR√çTICO) - 3 cards

#### FI-CORE-FEAT-001 - LLM Router con Abstracci√≥n Multi-Provider
**Prioridad**: P0 | **Estimado**: 6h ‚Üí ~1.2h real

**Descripci√≥n**:
Implementar router LLM con **abstracci√≥n provider-agnostic**. Claude es provider inicial, pero dise√±o permite agregar Ollama/OpenAI sin cambiar API.

**Arquitectura**:
```python
# Interfaz abstracta
class LLMProvider(ABC):
    @abstractmethod
    def generate(self, prompt: str, **kwargs) -> str:
        pass

    @abstractmethod
    def embed(self, text: str) -> np.ndarray:
        pass

# Implementaciones
class ClaudeProvider(LLMProvider):
    # Usa anthropic SDK

class OllamaProvider(LLMProvider):
    # Usa requests a OLLAMA_BASE_URL (futuro)

class OpenAIProvider(LLMProvider):
    # Usa openai SDK (futuro)

# Router
def get_provider(provider_name: str) -> LLMProvider:
    if provider_name == "claude":
        return ClaudeProvider()
    elif provider_name == "ollama":
        return OllamaProvider()
    # ...
```

**Criterios de Aceptaci√≥n**:
- [ ] `backend/llm_router.py` con:
  - [ ] `LLMProvider` abstract class
  - [ ] `ClaudeProvider` implementation
  - [ ] `get_provider(name)` factory
  - [ ] `llm_generate(prompt, provider, **kwargs) ‚Üí str`
  - [ ] `llm_embed(text, provider) ‚Üí ndarray`
- [ ] `ClaudeProvider` usa `anthropic` library
- [ ] Auto-logging en `/audit_logs/` con `@require_audit_log`
- [ ] Manejo de errors: rate limits, API down, timeout
- [ ] Environment variable `CLAUDE_API_KEY` desde `.env`
- [ ] Tests unitarios (15+ tests):
  - [ ] Mocks de ClaudeProvider
  - [ ] Factory pattern
  - [ ] Error handling
  - [ ] Audit logging
- [ ] Cost tracking: tokens used, $ estimado

**Dependencias**:
- Requiere API key de Claude (Bernard configurar√° en `.env`)
- Librer√≠a: `anthropic>=0.8.0`

**Notas Importantes**:
- üéØ **NO hardcodear Claude** - todo debe pasar por abstracci√≥n
- üéØ Provider selection desde config (no hardcoded)
- üéØ Easy to add Ollama en Sprint 3 del roadmap

---

#### FI-CORE-FEAT-002 - CLI Interactivo `fi chat`
**Prioridad**: P0 | **Estimado**: 4h ‚Üí ~0.8h real

**Descripci√≥n**:
Comando `fi chat` para interacci√≥n directa con LLM, guardando autom√°ticamente en corpus.

**Criterios de Aceptaci√≥n**:
- [ ] CLI script `scripts/fi_cli.py` con subcomando `chat`
- [ ] Interfaz: `fi chat [--model MODEL] [--session SESSION_ID]`
- [ ] Flujo: Prompt ‚Üí LLM Router ‚Üí Append to HDF5
- [ ] Muestra respuesta en terminal con syntax highlighting
- [ ] Auto-genera `session_id` si no se provee
- [ ] Muestra stats al final: tokens used, cost estimado
- [ ] Tests de integraci√≥n (E2E con mock LLM)

**Ejemplo de uso**:
```bash
$ fi chat --model claude-3-5-sonnet-20241022
> ¬øQu√© es Free Intelligence?
[Respuesta del LLM]
---
Tokens: 150 | Cost: $0.003 | Session: session_20251029_143022
```

---

#### FI-CONFIG-FEAT-002 - fi.policy.yaml (LLM Policies)
**Prioridad**: P0 | **Estimado**: 3h ‚Üí ~0.6h real

**Descripci√≥n**:
Archivo de configuraci√≥n para pol√≠ticas de LLM: presupuestos, timeouts, fallback, provider selection.

**Schema YAML**:
```yaml
llm:
  primary_provider: "claude"      # claude | ollama | openai
  fallback_provider: "claude"     # Si primary falla
  enable_offline: false           # true cuando Ollama est√© ready

  providers:
    claude:
      model: "claude-3-5-sonnet-20241022"
      api_key_env: "CLAUDE_API_KEY"
      timeout_seconds: 30
      max_tokens: 4096
      temperature: 0.7

    ollama:
      base_url: "http://192.168.1.100:11434"  # NAS IP
      model: "qwen2:7b-instruct-q4_0"
      timeout_seconds: 12
      max_tokens: 2048

  budgets:
    max_cost_per_day: 10.0         # USD
    max_requests_per_hour: 100
    alert_threshold: 0.8           # Alert at 80% budget

  fallback_rules:
    - condition: "timeout"
      action: "use_fallback"
    - condition: "rate_limit"
      action: "exponential_backoff"
    - condition: "api_error"
      action: "use_fallback"

  logging:
    log_all_prompts: true
    log_all_responses: true
    log_token_usage: true
```

**Criterios de Aceptaci√≥n**:
- [ ] `config/fi.policy.yaml` creado con schema completo
- [ ] `backend/policy_loader.py` con:
  - [ ] `load_llm_policy() ‚Üí dict`
  - [ ] Validaci√≥n de schema (required fields)
  - [ ] Defaults si faltan valores
- [ ] Integraci√≥n con `llm_router.py`:
  - [ ] Leer `primary_provider` desde policy
  - [ ] Aplicar timeouts, max_tokens
  - [ ] Verificar budgets antes de llamada
- [ ] Tests unitarios (10+ tests):
  - [ ] Load valid policy
  - [ ] Missing fields ‚Üí defaults
  - [ ] Invalid provider ‚Üí error
  - [ ] Budget enforcement
- [ ] Documentaci√≥n: docs/llm-policy.md

**Notas**:
- üéØ Policy-driven design = easy to change provider sin tocar c√≥digo
- üéØ Budgets previenen costos runaway
- üéØ Fallback rules para resiliencia

---

#### FI-DATA-FEAT-002 - Append Interaction End-to-End
**Prioridad**: P0 | **Estimado**: 2h ‚Üí ~0.4h real

**Descripci√≥n**:
Completar flujo de `append_interaction()` con embeddings autom√°ticos usando provider de LLM.

**Criterios de Aceptaci√≥n**:
- [ ] `corpus_ops.append_interaction()` recibe prompt + response
- [ ] Embedding generation:
  - [ ] Llamar a `llm_embed(prompt + response)` usando provider
  - [ ] Si provider no soporta embed ‚Üí usar sentence-transformers local
- [ ] Llama a `append_embedding()` autom√°ticamente
- [ ] Logging de INTERACTION_APPENDED + EMBEDDING_APPENDED
- [ ] Tests con verificaci√≥n de corpus stats incrementales
- [ ] Documentaci√≥n de pipeline completo

**Notas**:
- Ya existe esqueleto en Sprint 1, solo falta integrar con LLM router
- Sentence-transformers como fallback si provider no tiene embeddings

---

### Tier 2: Search & Export (IMPORTANTE) - 3 cards

#### FI-SEARCH-FEAT-001 - Buscador Sem√°ntico B√°sico
**Prioridad**: P1 | **Estimado**: 4h ‚Üí ~0.8h real

**Descripci√≥n**:
B√∫squeda sem√°ntica sobre embeddings con cosine similarity.

**Criterios de Aceptaci√≥n**:
- [ ] `backend/search.py` con funci√≥n `semantic_search(query, top_k=5)`
- [ ] Genera embedding de query
- [ ] Calcula cosine similarity vs todos los embeddings en corpus
- [ ] Retorna top_k interactions con scores
- [ ] CLI: `fi search "query text"`
- [ ] Tests con corpus sint√©tico (10 interactions)

---

#### FI-EXPORT-FEAT-001 - Exportador Markdown
**Prioridad**: P1 | **Estimado**: 3h ‚Üí ~0.6h real

**Descripci√≥n**:
Exportar interacciones a Markdown con manifest obligatorio (Export Policy).

**Criterios de Aceptaci√≥n**:
- [ ] `backend/exporter.py` con `export_to_markdown(filters, output_path)`
- [ ] Genera manifest con `export_policy.create_export_manifest()`
- [ ] Formato Markdown: `# Session XXXX\n## Interaction 1\n**Prompt**: ...\n**Response**: ...`
- [ ] Guarda manifest JSON junto al .md
- [ ] Append audit log (EXPORT_COMPLETED)
- [ ] CLI: `fi export markdown --session SESSION_ID --output exports/`
- [ ] Tests de formato y manifest validation

---

#### FI-EXPORT-FEAT-002 - Exportador JSON
**Prioridad**: P2 | **Estimado**: 2h ‚Üí ~0.4h real

**Descripci√≥n**:
Exportar interacciones a JSON estructurado.

**Criterios de Aceptaci√≥n**:
- [ ] `exporter.py` con `export_to_json(filters, output_path)`
- [ ] Schema JSON:
```json
{
  "export_id": "...",
  "timestamp": "...",
  "interactions": [
    {
      "interaction_id": "...",
      "session_id": "...",
      "timestamp": "...",
      "prompt": "...",
      "response": "...",
      "model": "...",
      "tokens": 123
    }
  ]
}
```
- [ ] Manifest obligatorio
- [ ] CLI: `fi export json`
- [ ] Tests JSON schema validation

---

### Tier 3: Observability & Polish (NICE TO HAVE) - 2 cards

#### FI-CLI-FEAT-001 - CLI de Gesti√≥n Completa
**Prioridad**: P2 | **Estimado**: 3h ‚Üí ~0.6h real

**Descripci√≥n**:
Unificar comandos CLI bajo `fi` tool.

**Criterios de Aceptaci√≥n**:
- [ ] Script `fi` en ra√≠z del proyecto (Python)
- [ ] Subcomandos: chat, search, export, stats, init, validate
- [ ] Help integrado: `fi --help`, `fi chat --help`
- [ ] Tests de CLI con subprocess

---

#### FI-DATA-FEAT-008 - Corpus Stats Dashboard
**Prioridad**: P2 | **Estimado**: 2h ‚Üí ~0.4h real

**Descripci√≥n**:
CLI para ver estad√≠sticas del corpus.

**Criterios de Aceptaci√≥n**:
- [ ] CLI: `fi stats [--detailed]`
- [ ] Muestra: Total interactions, sessions, embeddings, corpus size (MB)
- [ ] Breakdown por model used
- [ ] Audit logs stats (operations by type, last 7 days)
- [ ] Tests con corpus sint√©tico

---

## üìä Resumen de Carga

| Tier | Cards | Est Original | Est Real (vel 0.20) | Prioridad |
|------|-------|--------------|---------------------|-----------|
| **Tier 1** | 3 | 12h | ~2.4h | P0 (Cr√≠tico) |
| **Tier 2** | 3 | 9h | ~1.8h | P1 (Importante) |
| **Tier 3** | 2 | 5h | ~1h | P2 (Nice to have) |
| **Total** | **8** | **26h** | **~5.2h** | - |

**Capacidad Sprint 3**: 60h planificadas ‚Üí **~10-12h reales** con velocity 0.15-0.20

**Conclusi√≥n**: Scope es conservador. **Tier 1+2 (6 cards) son el MVP**. Tier 3 es bonus.

---

## üéØ Definition of Done (DoD)

Antes de mover card a "Done":

1. **Implementaci√≥n**:
   - [ ] C√≥digo implementado y funcional
   - [ ] Integrado con pol√≠ticas existentes (append-only, audit, etc.)
   - [ ] Logs con eventos can√≥nicos UPPER_SNAKE_CASE

2. **Testing**:
   - [ ] Tests unitarios (cobertura >80%)
   - [ ] Tests de integraci√≥n para flujos E2E
   - [ ] Validadores AST ejecutados sin violaciones

3. **Documentaci√≥n**:
   - [ ] Docstrings completos en funciones p√∫blicas
   - [ ] README.md actualizado si es feature visible
   - [ ] docs/ actualizado si hay nueva pol√≠tica o convenci√≥n

4. **Validaci√≥n**:
   - [ ] Pre-commit hooks pasan (6 validadores)
   - [ ] Tests completos pasan (259+ tests)
   - [ ] Demo manual ejecutado exitosamente

---

## üîê Requisitos Previos

### Environment Setup

Bernard deber√°:
1. Crear archivo `.env` en ra√≠z (gitignored):
   ```bash
   CLAUDE_API_KEY=sk-ant-api03-...
   ```
2. Instalar dependencias adicionales:
   ```bash
   pip3 install anthropic>=0.8.0 sentence-transformers>=2.2.0
   ```
3. Actualizar `requirements.txt` con versiones pinned

### API Key Security

‚ö†Ô∏è **CR√çTICO**:
- ‚ùå NUNCA commitear `.env`
- ‚ùå NUNCA poner API key en c√≥digo
- ‚úÖ Verificar `.gitignore` incluye `.env`
- ‚úÖ Usar `os.getenv("CLAUDE_API_KEY")` siempre

---

## üìÖ Timeline Sugerido (Flexible)

| D√≠as | Objetivo | Cards |
|------|----------|-------|
| D√≠a 1-2 | LLM Integration | FI-CORE-FEAT-001, FI-CORE-FEAT-002 |
| D√≠a 3 | Data Operations | FI-DATA-FEAT-002 |
| D√≠a 4-5 | Search & Export | FI-SEARCH-FEAT-001, FI-EXPORT-FEAT-001 |
| D√≠a 6 | Polish | FI-EXPORT-FEAT-002 (opcional) |
| D√≠a 7 | CLI Unification | FI-CLI-FEAT-001 (opcional) |

**Nota**: Con velocity 0.20, Tier 1+2 se completa en **~2-3 d√≠as reales** si hay foco.

---

## üöÄ Siguientes Fases (Post-Sprint 3)

### Sprint 4: UI & Visualization
- Dashboard local con timeline
- Visor de interacciones
- Gr√°ficos de uso y costos

### Sprint 5: Advanced Features
- Context window management
- Thread tracking
- Multi-model support (GPT-4, etc.)

### Sprint 6: Deployment & Scaling
- NAS deployment scripts
- Backup automation avanzado
- Network isolation (firewall rules)

---

## ü§î Decisiones Pendientes (para Bernard)

1. **¬øIniciar Sprint 3 ahora o tomar break?**
   - Sprint 2 completado 11-12 d√≠as adelante del plan
   - Opci√≥n: Descanso de 1-2 semanas antes de Sprint 3

2. **¬øQu√© cards de Tier 3 incluir?**
   - FI-CLI-FEAT-001 unifica comandos (recomendado)
   - FI-DATA-FEAT-008 stats dashboard (visual, nice to have)

3. **¬øModel default para Sprint 3?**
   - `claude-3-5-sonnet-20241022` (balance cost/calidad)
   - O `claude-3-5-haiku` para desarrollo (m√°s barato)

4. **¬øTesting strategy?**
   - ¬øUsar mocks de anthropic o hacer calls reales (con cost)?
   - Recomendaci√≥n: Mocks para unit tests, 1-2 calls reales para E2E

---

## ‚úÖ Checklist de Inicio Sprint 3

Antes de empezar:
- [ ] Bernard aprueba este plan (revisar scope, timeline)
- [ ] API key de Claude configurada en `.env`
- [ ] Dependencies instaladas: `anthropic`, `sentence-transformers`
- [ ] `requirements.txt` actualizado con nuevas deps
- [ ] `.gitignore` verificado (incluye `.env`)
- [ ] Crear cards en Trello (To Do Sprint column)
- [ ] Crear SPRINT_3_TRACKER.md (basado en template Sprint 2)
- [ ] Tag v0.3.0 verificado (ya existe)

---

**√öltima actualizaci√≥n**: 2025-10-28
**Estado**: Borrador - Pendiente aprobaci√≥n Bernard
**Siguiente acci√≥n**: Bernard revisa plan ‚Üí Aprueba/ajusta ‚Üí Inicia Sprint 3

---

