# Sprint 3 (SPR-2025W45-46) - AbstracciÃ³n LLM

**Inicio**: 2025-10-28 (AHORA - Bernard tiene 5h disponibles)
**Fin**: 2025-10-29 (1-2 dÃ­as, flexible)
**Tema**: "LLM Abstraction Layer - PreparaciÃ³n para Offline-First"
**Estado**: EN EJECUCIÃ“N âœ…
**Roadmap**: Este es el **Sprint 1 del Roadmap Offline-First** (ver `ROADMAP_OFFLINE_FIRST.md`)

---

## ğŸ¯ VisiÃ³n del Sprint (ACTUALIZADA - Offline-First)

Sprint 3 marca la **transiciÃ³n crÃ­tica hacia autonomÃ­a arquitectÃ³nica**. No es solo "hacer funcionar Claude API" - es **diseÃ±ar la abstracciÃ³n que nos libere de cualquier proveedor SaaS**.

**Cambio de FilosofÃ­a**:
- âŒ **Antes**: "Implementar Claude API y usarlo"
- âœ… **Ahora**: "Abstraer LLM para que Claude sea solo 1 de N proveedores"

**Objetivo Principal**:
1. **Interfaz Ãºnica LLM**: `llm.generate()`, `llm.embed()`, `llm.summarize()`
2. **Router inteligente**: SelecciÃ³n de provider (Claude hoy, Ollama maÃ±ana)
3. **Policy-driven**: Presupuestos, timeouts, fallback en `fi.policy.yaml`
4. **Future-proof**: Cuando instalemos Ollama (Sprint 3 roadmap), solo cambiar config

**Flujo Objetivo**: **Prompt â†’ Router â†’ [Claude | Ollama | ...] â†’ Corpus â†’ Search/Export**

---

## ğŸ“Š AnÃ¡lisis Post-Sprint 2

### Velocity Observada

| Sprint | Horas Est | Horas Reales | Cards | Velocity |
|--------|-----------|--------------|-------|----------|
| Sprint 1 | 18h | 1.05h | 5 | 0.06 |
| Sprint 2 | ~40h | ~8h | 12 | 0.20 |
| **Promedio** | **~29h** | **~4.5h** | **8.5** | **0.13** |

**Observaciones**:
- Velocity mejorÃ³ 3.3x entre Sprint 1 y 2
- Sprint 2 se completÃ³ en **3/15 dÃ­as** (20% del tiempo planificado)
- Bernard tiene alta capacidad de ejecuciÃ³n en sesiones concentradas
- Estimaciones consistentemente pesimistas (factor ~5-8x)

### Lecciones Aprendidas

âœ… **FuncionÃ³ bien**:
- Cards pequeÃ±as y bien definidas (1-5h est)
- Foco en polÃ­ticas y enforcement (AST validators)
- Tests unitarios comprehensivos
- DocumentaciÃ³n inline durante implementaciÃ³n
- Sprint-close automation

âš ï¸ **Mejorar**:
- Estimar con velocity real (~0.15-0.20, no 0.06)
- Menos buffer time (Bernard ejecuta rÃ¡pido)
- Definir criterios de aceptaciÃ³n mÃ¡s especÃ­ficos
- Testing E2E automatizado (no solo unit tests)

---

## ğŸ—ï¸ Arquitectura Objetivo Sprint 3

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Capa 5: User Interface (CLI)          â”‚
â”‚  âœ… Comandos bÃ¡sicos                    â”‚
â”‚  ğŸ¯ NEW: fi chat, fi search, fi export â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Capa 4: LLM Integration                â”‚
â”‚  ğŸ¯ NEW: LLM Router (anthropic)         â”‚
â”‚  ğŸ¯ NEW: Auto-audit logging             â”‚
â”‚  ğŸ¯ NEW: Cost tracking                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Capa 3: Data Operations                â”‚
â”‚  âœ… Append interaction (Sprint 1)       â”‚
â”‚  ğŸ¯ NEW: Semantic search (embeddings)   â”‚
â”‚  ğŸ¯ NEW: Export engines (MD, JSON)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Capa 2: Foundation (Sprint 1+2)        â”‚
â”‚  âœ… HDF5 Schema, Audit Logs, Policies   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ Cards Propuestas (Tier System)

### Tier 1: LLM Abstraction Layer (CRÃTICO) - 3 cards

#### FI-CORE-FEAT-001 - LLM Router con AbstracciÃ³n Multi-Provider
**Prioridad**: P0 | **Estimado**: 6h â†’ ~1.2h real

**DescripciÃ³n**:
Implementar router LLM con **abstracciÃ³n provider-agnostic**. Claude es provider inicial, pero diseÃ±o permite agregar Ollama/OpenAI sin cambiar API.

**Arquitectura**:
```python
# Interfaz abstracta
class LLMProvider(ABC):
    @abstractmethod
    def generate(self, prompt: str, **kwargs) -> str:
        pass

    @abstractmethod
    def embed(self, text: str) -> np.ndarray:
        pass

# Implementaciones
class ClaudeProvider(LLMProvider):
    # Usa anthropic SDK

class OllamaProvider(LLMProvider):
    # Usa requests a OLLAMA_BASE_URL (futuro)

class OpenAIProvider(LLMProvider):
    # Usa openai SDK (futuro)

# Router
def get_provider(provider_name: str) -> LLMProvider:
    if provider_name == "claude":
        return ClaudeProvider()
    elif provider_name == "ollama":
        return OllamaProvider()
    # ...
```

**Criterios de AceptaciÃ³n**:
- [ ] `backend/llm_router.py` con:
  - [ ] `LLMProvider` abstract class
  - [ ] `ClaudeProvider` implementation
  - [ ] `get_provider(name)` factory
  - [ ] `llm_generate(prompt, provider, **kwargs) â†’ str`
  - [ ] `llm_embed(text, provider) â†’ ndarray`
- [ ] `ClaudeProvider` usa `anthropic` library
- [ ] Auto-logging en `/audit_logs/` con `@require_audit_log`
- [ ] Manejo de errors: rate limits, API down, timeout
- [ ] Environment variable `CLAUDE_API_KEY` desde `.env`
- [ ] Tests unitarios (15+ tests):
  - [ ] Mocks de ClaudeProvider
  - [ ] Factory pattern
  - [ ] Error handling
  - [ ] Audit logging
- [ ] Cost tracking: tokens used, $ estimado

**Dependencias**:
- Requiere API key de Claude (Bernard configurarÃ¡ en `.env`)
- LibrerÃ­a: `anthropic>=0.8.0`

**Notas Importantes**:
- ğŸ¯ **NO hardcodear Claude** - todo debe pasar por abstracciÃ³n
- ğŸ¯ Provider selection desde config (no hardcoded)
- ğŸ¯ Easy to add Ollama en Sprint 3 del roadmap

---

#### FI-CORE-FEAT-002 - CLI Interactivo `fi chat`
**Prioridad**: P0 | **Estimado**: 4h â†’ ~0.8h real

**DescripciÃ³n**:
Comando `fi chat` para interacciÃ³n directa con LLM, guardando automÃ¡ticamente en corpus.

**Criterios de AceptaciÃ³n**:
- [ ] CLI script `scripts/fi_cli.py` con subcomando `chat`
- [ ] Interfaz: `fi chat [--model MODEL] [--session SESSION_ID]`
- [ ] Flujo: Prompt â†’ LLM Router â†’ Append to HDF5
- [ ] Muestra respuesta en terminal con syntax highlighting
- [ ] Auto-genera `session_id` si no se provee
- [ ] Muestra stats al final: tokens used, cost estimado
- [ ] Tests de integraciÃ³n (E2E con mock LLM)

**Ejemplo de uso**:
```bash
$ fi chat --model claude-3-5-sonnet-20241022
> Â¿QuÃ© es Free Intelligence?
[Respuesta del LLM]
---
Tokens: 150 | Cost: $0.003 | Session: session_20251029_143022
```

---

#### FI-CONFIG-FEAT-002 - fi.policy.yaml (LLM Policies)
**Prioridad**: P0 | **Estimado**: 3h â†’ ~0.6h real

**DescripciÃ³n**:
Archivo de configuraciÃ³n para polÃ­ticas de LLM: presupuestos, timeouts, fallback, provider selection.

**Schema YAML**:
```yaml
llm:
  primary_provider: "claude"      # claude | ollama | openai
  fallback_provider: "claude"     # Si primary falla
  enable_offline: false           # true cuando Ollama estÃ© ready

  providers:
    claude:
      model: "claude-3-5-sonnet-20241022"
      api_key_env: "CLAUDE_API_KEY"
      timeout_seconds: 30
      max_tokens: 4096
      temperature: 0.7

    ollama:
      base_url: "http://192.168.1.100:11434"  # NAS IP
      model: "qwen2:7b-instruct-q4_0"
      timeout_seconds: 12
      max_tokens: 2048

  budgets:
    max_cost_per_day: 10.0         # USD
    max_requests_per_hour: 100
    alert_threshold: 0.8           # Alert at 80% budget

  fallback_rules:
    - condition: "timeout"
      action: "use_fallback"
    - condition: "rate_limit"
      action: "exponential_backoff"
    - condition: "api_error"
      action: "use_fallback"

  logging:
    log_all_prompts: true
    log_all_responses: true
    log_token_usage: true
```

**Criterios de AceptaciÃ³n**:
- [ ] `config/fi.policy.yaml` creado con schema completo
- [ ] `backend/policy_loader.py` con:
  - [ ] `load_llm_policy() â†’ dict`
  - [ ] ValidaciÃ³n de schema (required fields)
  - [ ] Defaults si faltan valores
- [ ] IntegraciÃ³n con `llm_router.py`:
  - [ ] Leer `primary_provider` desde policy
  - [ ] Aplicar timeouts, max_tokens
  - [ ] Verificar budgets antes de llamada
- [ ] Tests unitarios (10+ tests):
  - [ ] Load valid policy
  - [ ] Missing fields â†’ defaults
  - [ ] Invalid provider â†’ error
  - [ ] Budget enforcement
- [ ] DocumentaciÃ³n: docs/llm-policy.md

**Notas**:
- ğŸ¯ Policy-driven design = easy to change provider sin tocar cÃ³digo
- ğŸ¯ Budgets previenen costos runaway
- ğŸ¯ Fallback rules para resiliencia

---

#### FI-DATA-FEAT-002 - Append Interaction End-to-End
**Prioridad**: P0 | **Estimado**: 2h â†’ ~0.4h real

**DescripciÃ³n**:
Completar flujo de `append_interaction()` con embeddings automÃ¡ticos usando provider de LLM.

**Criterios de AceptaciÃ³n**:
- [ ] `corpus_ops.append_interaction()` recibe prompt + response
- [ ] Embedding generation:
  - [ ] Llamar a `llm_embed(prompt + response)` usando provider
  - [ ] Si provider no soporta embed â†’ usar sentence-transformers local
- [ ] Llama a `append_embedding()` automÃ¡ticamente
- [ ] Logging de INTERACTION_APPENDED + EMBEDDING_APPENDED
- [ ] Tests con verificaciÃ³n de corpus stats incrementales
- [ ] DocumentaciÃ³n de pipeline completo

**Notas**:
- Ya existe esqueleto en Sprint 1, solo falta integrar con LLM router
- Sentence-transformers como fallback si provider no tiene embeddings

---

### Tier 2: Search & Export (IMPORTANTE) - 3 cards

#### FI-SEARCH-FEAT-001 - Buscador SemÃ¡ntico BÃ¡sico
**Prioridad**: P1 | **Estimado**: 4h â†’ ~0.8h real

**DescripciÃ³n**:
BÃºsqueda semÃ¡ntica sobre embeddings con cosine similarity.

**Criterios de AceptaciÃ³n**:
- [ ] `backend/search.py` con funciÃ³n `semantic_search(query, top_k=5)`
- [ ] Genera embedding de query
- [ ] Calcula cosine similarity vs todos los embeddings en corpus
- [ ] Retorna top_k interactions con scores
- [ ] CLI: `fi search "query text"`
- [ ] Tests con corpus sintÃ©tico (10 interactions)

---

#### FI-EXPORT-FEAT-001 - Exportador Markdown
**Prioridad**: P1 | **Estimado**: 3h â†’ ~0.6h real

**DescripciÃ³n**:
Exportar interacciones a Markdown con manifest obligatorio (Export Policy).

**Criterios de AceptaciÃ³n**:
- [ ] `backend/exporter.py` con `export_to_markdown(filters, output_path)`
- [ ] Genera manifest con `export_policy.create_export_manifest()`
- [ ] Formato Markdown: `# Session XXXX\n## Interaction 1\n**Prompt**: ...\n**Response**: ...`
- [ ] Guarda manifest JSON junto al .md
- [ ] Append audit log (EXPORT_COMPLETED)
- [ ] CLI: `fi export markdown --session SESSION_ID --output exports/`
- [ ] Tests de formato y manifest validation

---

#### FI-EXPORT-FEAT-002 - Exportador JSON
**Prioridad**: P2 | **Estimado**: 2h â†’ ~0.4h real

**DescripciÃ³n**:
Exportar interacciones a JSON estructurado.

**Criterios de AceptaciÃ³n**:
- [ ] `exporter.py` con `export_to_json(filters, output_path)`
- [ ] Schema JSON:
```json
{
  "export_id": "...",
  "timestamp": "...",
  "interactions": [
    {
      "interaction_id": "...",
      "session_id": "...",
      "timestamp": "...",
      "prompt": "...",
      "response": "...",
      "model": "...",
      "tokens": 123
    }
  ]
}
```
- [ ] Manifest obligatorio
- [ ] CLI: `fi export json`
- [ ] Tests JSON schema validation

---

### Tier 3: Observability & Polish (NICE TO HAVE) - 2 cards

#### FI-CLI-FEAT-001 - CLI de GestiÃ³n Completa
**Prioridad**: P2 | **Estimado**: 3h â†’ ~0.6h real

**DescripciÃ³n**:
Unificar comandos CLI bajo `fi` tool.

**Criterios de AceptaciÃ³n**:
- [ ] Script `fi` en raÃ­z del proyecto (Python)
- [ ] Subcomandos: chat, search, export, stats, init, validate
- [ ] Help integrado: `fi --help`, `fi chat --help`
- [ ] Tests de CLI con subprocess

---

#### FI-DATA-FEAT-008 - Corpus Stats Dashboard
**Prioridad**: P2 | **Estimado**: 2h â†’ ~0.4h real

**DescripciÃ³n**:
CLI para ver estadÃ­sticas del corpus.

**Criterios de AceptaciÃ³n**:
- [ ] CLI: `fi stats [--detailed]`
- [ ] Muestra: Total interactions, sessions, embeddings, corpus size (MB)
- [ ] Breakdown por model used
- [ ] Audit logs stats (operations by type, last 7 days)
- [ ] Tests con corpus sintÃ©tico

---

## ğŸ“Š Resumen de Carga

| Tier | Cards | Est Original | Est Real (vel 0.20) | Prioridad |
|------|-------|--------------|---------------------|-----------|
| **Tier 1** | 3 | 12h | ~2.4h | P0 (CrÃ­tico) |
| **Tier 2** | 3 | 9h | ~1.8h | P1 (Importante) |
| **Tier 3** | 2 | 5h | ~1h | P2 (Nice to have) |
| **Total** | **8** | **26h** | **~5.2h** | - |

**Capacidad Sprint 3**: 60h planificadas â†’ **~10-12h reales** con velocity 0.15-0.20

**ConclusiÃ³n**: Scope es conservador. **Tier 1+2 (6 cards) son el MVP**. Tier 3 es bonus.

---

## ğŸ¯ Definition of Done (DoD)

Antes de mover card a "Done":

1. **ImplementaciÃ³n**:
   - [ ] CÃ³digo implementado y funcional
   - [ ] Integrado con polÃ­ticas existentes (append-only, audit, etc.)
   - [ ] Logs con eventos canÃ³nicos UPPER_SNAKE_CASE

2. **Testing**:
   - [ ] Tests unitarios (cobertura >80%)
   - [ ] Tests de integraciÃ³n para flujos E2E
   - [ ] Validadores AST ejecutados sin violaciones

3. **DocumentaciÃ³n**:
   - [ ] Docstrings completos en funciones pÃºblicas
   - [ ] README.md actualizado si es feature visible
   - [ ] docs/ actualizado si hay nueva polÃ­tica o convenciÃ³n

4. **ValidaciÃ³n**:
   - [ ] Pre-commit hooks pasan (6 validadores)
   - [ ] Tests completos pasan (259+ tests)
   - [ ] Demo manual ejecutado exitosamente

---

## ğŸ” Requisitos Previos

### Environment Setup

Bernard deberÃ¡:
1. Crear archivo `.env` en raÃ­z (gitignored):
   ```bash
   CLAUDE_API_KEY=sk-ant-api03-...
   ```
2. Instalar dependencias adicionales:
   ```bash
   pip3 install anthropic>=0.8.0 sentence-transformers>=2.2.0
   ```
3. Actualizar `requirements.txt` con versiones pinned

### API Key Security

âš ï¸ **CRÃTICO**:
- âŒ NUNCA commitear `.env`
- âŒ NUNCA poner API key en cÃ³digo
- âœ… Verificar `.gitignore` incluye `.env`
- âœ… Usar `os.getenv("CLAUDE_API_KEY")` siempre

---

## ğŸ“… Timeline Sugerido (Flexible)

| DÃ­as | Objetivo | Cards |
|------|----------|-------|
| DÃ­a 1-2 | LLM Integration | FI-CORE-FEAT-001, FI-CORE-FEAT-002 |
| DÃ­a 3 | Data Operations | FI-DATA-FEAT-002 |
| DÃ­a 4-5 | Search & Export | FI-SEARCH-FEAT-001, FI-EXPORT-FEAT-001 |
| DÃ­a 6 | Polish | FI-EXPORT-FEAT-002 (opcional) |
| DÃ­a 7 | CLI Unification | FI-CLI-FEAT-001 (opcional) |

**Nota**: Con velocity 0.20, Tier 1+2 se completa en **~2-3 dÃ­as reales** si hay foco.

---

## ğŸš€ Siguientes Fases (Post-Sprint 3)

### Sprint 4: UI & Visualization
- Dashboard local con timeline
- Visor de interacciones
- GrÃ¡ficos de uso y costos

### Sprint 5: Advanced Features
- Context window management
- Thread tracking
- Multi-model support (GPT-4, etc.)

### Sprint 6: Deployment & Scaling
- NAS deployment scripts
- Backup automation avanzado
- Network isolation (firewall rules)

---

## ğŸ¤” Decisiones Pendientes (para Bernard)

1. **Â¿Iniciar Sprint 3 ahora o tomar break?**
   - Sprint 2 completado 11-12 dÃ­as adelante del plan
   - OpciÃ³n: Descanso de 1-2 semanas antes de Sprint 3

2. **Â¿QuÃ© cards de Tier 3 incluir?**
   - FI-CLI-FEAT-001 unifica comandos (recomendado)
   - FI-DATA-FEAT-008 stats dashboard (visual, nice to have)

3. **Â¿Model default para Sprint 3?**
   - `claude-3-5-sonnet-20241022` (balance cost/calidad)
   - O `claude-3-5-haiku` para desarrollo (mÃ¡s barato)

4. **Â¿Testing strategy?**
   - Â¿Usar mocks de anthropic o hacer calls reales (con cost)?
   - RecomendaciÃ³n: Mocks para unit tests, 1-2 calls reales para E2E

---

## âœ… Checklist de Inicio Sprint 3

Antes de empezar:
- [ ] Bernard aprueba este plan (revisar scope, timeline)
- [ ] API key de Claude configurada en `.env`
- [ ] Dependencies instaladas: `anthropic`, `sentence-transformers`
- [ ] `requirements.txt` actualizado con nuevas deps
- [ ] `.gitignore` verificado (incluye `.env`)
- [ ] Crear cards en Trello (To Do Sprint column)
- [ ] Crear SPRINT_3_TRACKER.md (basado en template Sprint 2)
- [ ] Tag v0.3.0 verificado (ya existe)

---

**Ãšltima actualizaciÃ³n**: 2025-10-28
**Estado**: Borrador - Pendiente aprobaciÃ³n Bernard
**Siguiente acciÃ³n**: Bernard revisa plan â†’ Aprueba/ajusta â†’ Inicia Sprint 3

---

