# Error Budgets & SLO Policy

**Card**: FI-RELIABILITY-STR-001
**Axioma**: Materia = Glitch Elegante
**Owner**: SRE / Platform Team
**Version**: 1.0.0
**Date**: 2025-10-29

---

## Filosof√≠a

> _"La materia es glitch elegante. No combatimos la entrop√≠a, la administramos."_

Free Intelligence adopta error budgets como reconocimiento de que **100% uptime es mentira**. En lugar de promesas imposibles, establecemos presupuestos realistas de fallas permitidas.

---

## Service Level Objectives (SLOs)

| Servicio | M√©trica | Target (SLO) | Error Budget | Ventana |
|----------|---------|--------------|-------------|---------|
| **Ingestion API** | p95 latency | <2s | 5% de requests pueden fallar | 30 d√≠as |
| **Timeline API** | p99 latency | <100ms | 1% pueden exceder | 7 d√≠as |
| **Verify API** | p95 latency | <500ms | 3% pueden fallar | 30 d√≠as |
| **Corpus HDF5 writes** | Success rate | 99.9% | 0.1% fallos permitidos | 30 d√≠as |
| **LLM routing** | Timeout rate | <1% | 1% requests pueden timeout | 7 d√≠as |

---

## C√°lculo de Error Budget

**F√≥rmula**:
```
Error Budget = (1 - SLO) √ó Total Requests
```

**Ejemplo**: Timeline API
- SLO: 99% de requests <100ms (p99)
- Requests mensuales: 100,000
- Error budget: (1 - 0.99) √ó 100,000 = **1,000 requests lentos permitidos**

**Consumo**:
- Si en la semana 1 tuvimos 300 requests >100ms, consumimos 30% del budget mensual
- Quedan 700 requests "lentos" permitidos para el resto del mes

---

## Acciones por Consumo de Budget

| Budget Restante | Acci√≥n | Owner | Ejemplo |
|-----------------|--------|-------|---------|
| **>75%** | ‚úÖ Normal operations | Dev team | Deployments sin restricci√≥n |
| **50-75%** | ‚ö†Ô∏è Monitor closely | SRE | Review logs diarios, alertas Slack |
| **25-50%** | üö® Freeze risky deployments | Tech Lead | Solo hotfixes cr√≠ticos |
| **<25%** | üî¥ **Emergency mode** | CTO | Rollback, incident post-mortem |

---

## Pol√≠ticas de Degradaci√≥n Suave

### 1. **Back-Pressure en Ingestion**
**Trigger**: p95 latency >3s (150% del SLO)
**Acci√≥n**:
- Activar rate limiting (50 req/s ‚Üí 25 req/s)
- Retornar HTTP 429 con `Retry-After` header
- Log en audit trail: `BACKPRESSURE_ACTIVATED`

**C√≥digo**:
```python
if p95_latency > 3.0:
    rate_limiter.reduce_by(50%)
    logger.warn("BACKPRESSURE_ACTIVATED", latency=p95_latency)
```

---

### 2. **Circuit Breaker en LLM Router**
**Trigger**: Timeout rate >2% en 5min
**Acci√≥n**:
- Abrir circuit breaker
- Fallback a cached responses (si disponible)
- Modo degradado: respuestas simplificadas

**Duraci√≥n**: 1 minuto antes de retry half-open

---

### 3. **Queue Shedding en Corpus Writes**
**Trigger**: Queue depth >10,000 items
**Acci√≥n**:
- Shed lowest-priority items (analytics, embeddings)
- Preservar writes cr√≠ticos (interactions, metadata)
- Alert: `QUEUE_SHEDDING_ACTIVE`

**Prioridad**:
1. Interactions (cr√≠tico)
2. Metadata (alto)
3. Embeddings (medio)
4. Analytics (bajo)

---

## Chaos Engineering Drills

### Drill Schedule (Mensual)

| Mes | Drill Type | Objetivo | Owner | Fecha |
|-----|-----------|----------|-------|-------|
| Nov 2025 | **Network partition** | Verificar queue resilience | SRE | 2025-11-15 |
| Dec 2025 | **Corpus file lock** | Test retry logic | Backend | 2025-12-20 |
| Jan 2026 | **LLM API timeout** | Validate circuit breaker | ML Ops | 2026-01-17 |
| Feb 2026 | **Disk full (90%)** | Log rotation & cleanup | Infra | 2026-02-14 |

### Drill Protocol

**Pre-drill** (1 semana antes):
1. Announce en #sre canal
2. Crear rollback plan
3. Definir success criteria
4. Preparar monitoring dashboards

**During drill** (30-60 min):
1. Ejecutar chaos injection (ej. `iptables DROP`)
2. Monitor dashboards en tiempo real
3. Validar auto-recovery
4. Documentar observaciones

**Post-drill** (1-2 d√≠as despu√©s):
1. Write post-mortem (incluso si fue exitoso)
2. Update runbooks con learnings
3. File issues para mejoras detectadas
4. Update ERROR_BUDGETS.md con nuevos SLOs si necesario

---

## Monitoring & Alerting

### Dashboards Requeridos

**1. Error Budget Dashboard**
- Budget restante (gauge)
- Consumo semanal (line chart)
- Top 5 endpoints consumidores
- Proyecci√≥n de agotamiento (si contin√∫a trend)

**2. Latency Heatmap**
- p50, p95, p99 por endpoint
- Color coding: verde <SLO, amarillo 100-150% SLO, rojo >150%

**3. Incident Timeline**
- Eventos de backpressure
- Circuit breaker activations
- Queue shedding episodes

### Alertas (Slack + Email)

| Condici√≥n | Severidad | Destinatarios | Ejemplo |
|-----------|-----------|---------------|---------|
| Budget <50% | WARNING | #sre | "Timeline API budget at 48% (12 days remaining)" |
| Budget <25% | CRITICAL | @tech-lead, #incidents | "EMERGENCY: Ingestion budget at 18%" |
| SLO breach >2h | INCIDENT | @oncall, @cto | "p95 latency >2s for 2.5h" |
| Chaos drill start | INFO | #general | "üî• Chaos drill: Network partition starting" |

---

## Revisi√≥n & Ajuste

**Frecuencia**: Trimestral

**Preguntas**:
1. ¬øLos SLOs son muy estrictos? (budget siempre >90%)
2. ¬øMuy laxos? (budget agot√°ndose constantemente)
3. ¬øNuevos servicios requieren SLOs?
4. ¬øChaos drills revelaron gaps en policies?

**Output**: Updated ERROR_BUDGETS.md con nuevos targets

---

## Referencias

- **Axioma**: `docs/PHILOSOPHY_CORPUS.md` (Materia = Glitch Elegante)
- **Mapping**: `docs/PHI_MAPPING.md`
- **Incident Runbooks**: `docs/runbooks/`
- **SRE Handbook**: Google SRE Book, Chapter 3-4

---

## Anexo: Ejemplo de Post-Mortem

**Incident**: Timeline API p99 >500ms durante 3h (2025-10-15)

**Impact**: 20% de error budget consumido en 1 d√≠a

**Root Cause**: Corpus file lock contention (10+ concurrent reads)

**Resolution**: Implemented read-side caching (Redis) para metadata

**Prevention**: Added drill "Corpus lock storm" para Feb 2026

**Action Items**:
- [x] Deploy Redis cache (FI-PERF-FEAT-001)
- [x] Add cache hit rate to dashboard
- [ ] Benchmark with 100 concurrent reads (FI-TEST-PERF-002)

---

_"El glitch no es el enemigo. El enemigo es no tener presupuesto para √©l."_
